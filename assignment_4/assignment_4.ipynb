{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d0aa1f3d",
   "metadata": {},
   "source": [
    "## Assignment 4 – Local features matching and Harris corner detection\n",
    "*IKT213 Machine Vision*\n",
    "\n",
    "**Name:** Maximilian Eckstein  \n",
    "**Date:** 19.10.2025\n",
    "\n",
    "This notebook implements the two required tasks:\n",
    "\n",
    "1. **Harris Corner Detection** on the reference image – saves `results/harris.png` (PDF page 1).  \n",
    "2. **Feature-based alignment** using **SIFT + FLANN + Homography** – saves `results/aligned.png` (PDF page 2) and `results/matches.png` (PDF page 3).\n",
    "\n",
    "Finally, it builds a **3-page PDF** `results/assignment_4_pages.pdf` containing the three outputs in the required order.\n",
    "\n",
    "### Use of ChatGPT (transparency)\n",
    "I used ChatGPT to:\n",
    "- evaluate and compare OpenCV tutorial code variants (SIFT / ORB / FLANN),\n",
    "- comment and document the functions,\n",
    "- set up the PDF export cell and captions,\n",
    "- align the final implementation with the assignment requirements.  \n",
    "All functions were implemented following the referenced OpenCV tutorials and course guidelines.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "44dc307b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Setup ===\n",
    "import os\n",
    "from pathlib import Path\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Output folder\n",
    "res_path = Path(\"results\")\n",
    "res_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Load inputs once (BGR)\n",
    "ref_img_color = cv2.imread(\"reference_img.png\", cv2.IMREAD_COLOR)\n",
    "tgt_img_color = cv2.imread(\"align_this.jpg\",   cv2.IMREAD_COLOR)\n",
    "\n",
    "if ref_img_color is None or tgt_img_color is None:\n",
    "    raise FileNotFoundError(\"Please place 'reference_img.png' and 'align_this.jpg' next to this notebook.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29b58d1f",
   "metadata": {},
   "source": [
    "### 1) Harris Corner Detection\n",
    "\n",
    "We follow the standard Harris pipeline:  \n",
    "grayscale → cornerHarris → dilate → threshold & mark on the original image (red).  \n",
    "Saves `results/harris.png`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "a1786fbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: results/harris.png\n"
     ]
    }
   ],
   "source": [
    "def harris_corner_detection(reference_image_bgr):\n",
    "    \"\"\"\n",
    "    Harris Corner Detection (visualization).\n",
    "    - Input: reference_image_bgr (BGR color image)\n",
    "    - Output (saved): results/harris.png\n",
    "    \"\"\"\n",
    "    gray = cv2.cvtColor(reference_image_bgr, cv2.COLOR_BGR2GRAY)\n",
    "    gray_f = np.float32(gray)\n",
    "\n",
    "    # Harris parameters (standard choices)\n",
    "    dst = cv2.cornerHarris(gray_f, blockSize=2, ksize=3, k=0.04)\n",
    "    dst = cv2.dilate(dst, None)  # visualization only\n",
    "\n",
    "    vis = reference_image_bgr.copy()\n",
    "    vis[dst > 0.01 * dst.max()] = [0, 0, 255]  # mark corners in red (BGR)\n",
    "\n",
    "    out_path = res_path / \"harris.png\"\n",
    "    cv2.imwrite(str(out_path), vis)\n",
    "\n",
    "harris_out = harris_corner_detection(ref_img_color)\n",
    "print(f\"Saved: {res_path}/harris.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb3e993e",
   "metadata": {},
   "source": [
    "### 2) Feature-Based Image Alignment – SIFT + FLANN + Homography\n",
    "\n",
    "**Important interpretation of the assignment parameters (consistent with the OpenCV tutorial):**\n",
    "- `good_match_precent = 0.7` → **Lowe-ratio threshold** (`m.distance < 0.7 * n.distance`).\n",
    "- `max_features = 10` → interpreted as **minimum number of “good” matches** required to attempt a homography (`MIN_MATCH_COUNT = 10`),  \n",
    "  not as “limit SIFT to 10 keypoints.”  \n",
    "  Limiting SIFT to 10 keypoints usually prevents finding ≥4 inliers after ratio + RANSAC, which means no homography and thus no `aligned.png`.\n",
    "\n",
    "**Workflow (tutorial-faithful):**\n",
    "1. Detect & describe SIFT on reference (img1) and target (img2).  \n",
    "2. FLANN (KD-Tree) + kNN matches, Lowe-ratio at 0.7.  \n",
    "3. Require at least `MIN_MATCH_COUNT = 10` good matches (tutorial threshold).  \n",
    "4. Estimate **H: Ref → Target** with RANSAC.  \n",
    "5. For alignment, we need **Target → Ref**, so we use **inverse** `H⁻¹` to warp the target into the reference frame.  \n",
    "6. Save `results/aligned.png` and `results/matches.png`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "da8b9f87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: results/aligned.png\n",
      "Saved: results/matches.png\n"
     ]
    }
   ],
   "source": [
    "def align_images_sift(image_to_align_bgr, reference_image_bgr,\n",
    "                      max_features=10, good_match_precent=0.7):\n",
    "    \"\"\"\n",
    "    Align `image_to_align_bgr` onto `reference_image_bgr` using SIFT + FLANN + Homography.\n",
    "\n",
    "    Parameters (assignment-consistent & tutorial-faithful):\n",
    "      - good_match_precent (0.7): Lowe-ratio threshold.\n",
    "      - max_features (10): used as MIN_MATCH_COUNT = 10 (minimum #good matches before homography),\n",
    "        NOT as a hard limit on SIFT keypoints (limiting SIFT to 10 typically breaks homography).\n",
    "\n",
    "    Outputs (saved to 'results/'):\n",
    "      - aligned.png : target warped into the reference frame (page 2)\n",
    "      - matches.png : inlier matches visualization (page 3)\n",
    "\n",
    "    Returns:\n",
    "      - H_tgt2ref (3x3): homography mapping target -> reference\n",
    "    \"\"\"\n",
    "    # Convert to grayscale for feature extraction\n",
    "    ref_gray = cv2.cvtColor(reference_image_bgr, cv2.COLOR_BGR2GRAY)  # img1 (reference)\n",
    "    tgt_gray = cv2.cvtColor(image_to_align_bgr,  cv2.COLOR_BGR2GRAY)  # img2 (target)\n",
    "\n",
    "    # SIFT (do NOT clamp to 10)\n",
    "    sift = cv2.SIFT_create()\n",
    "    kp1, des1 = sift.detectAndCompute(ref_gray, None)\n",
    "    kp2, des2 = sift.detectAndCompute(tgt_gray, None)\n",
    "    if des1 is None or des2 is None or len(kp1) < 2 or len(kp2) < 2:\n",
    "        vis = cv2.drawKeypoints(ref_gray, kp1 or [], None, color=(0, 255, 0))\n",
    "        cv2.imwrite(str(res_path / \"matches.png\"), vis)\n",
    "        raise RuntimeError(\"Not enough SIFT features detected.\")\n",
    "\n",
    "    # FLANN (KD-Tree) + kNN (tutorial)\n",
    "    FLANN_INDEX_KDTREE = 1\n",
    "    flann = cv2.FlannBasedMatcher(dict(algorithm=FLANN_INDEX_KDTREE, trees=5),\n",
    "                                  dict(checks=50))\n",
    "    knn = flann.knnMatch(des1, des2, k=2)  # Ref -> Target\n",
    "\n",
    "    # Lowe-ratio filter\n",
    "    ratio = float(good_match_precent)\n",
    "    good = [m for m, n in knn if m.distance < ratio * n.distance]\n",
    "\n",
    "    # Minimum good matches (interpret 'max_features=10' as MIN_MATCH_COUNT=10)\n",
    "    MIN_MATCH_COUNT = int(max_features) if max_features and max_features > 0 else 10\n",
    "    if len(good) <= MIN_MATCH_COUNT:\n",
    "        dbg = cv2.drawMatches(ref_gray, kp1, tgt_gray, kp2, good, None, flags=2)\n",
    "        cv2.imwrite(str(res_path / \"matches.png\"), dbg)\n",
    "        raise RuntimeError(f\"Not enough good matches: {len(good)} <= {MIN_MATCH_COUNT}\")\n",
    "\n",
    "    # Homography: Ref -> Target (tutorial order)\n",
    "    src_pts = np.float32([kp1[m.queryIdx].pt for m in good]).reshape(-1, 1, 2)  # ref\n",
    "    dst_pts = np.float32([kp2[m.trainIdx].pt for m in good]).reshape(-1, 1, 2)  # target\n",
    "    H_ref2tgt, mask = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC, 5.0)\n",
    "    if H_ref2tgt is None:\n",
    "        dbg = cv2.drawMatches(ref_gray, kp1, tgt_gray, kp2, good, None, flags=2)\n",
    "        cv2.imwrite(str(res_path / \"matches.png\"), dbg)\n",
    "        raise RuntimeError(\"Homography estimation failed (H=None).\")\n",
    "\n",
    "    # Warp: Target -> Reference (use inverse)\n",
    "    H_tgt2ref = np.linalg.inv(H_ref2tgt)\n",
    "    h, w = ref_gray.shape\n",
    "    aligned = cv2.warpPerspective(image_to_align_bgr, H_tgt2ref, (w, h))\n",
    "    cv2.imwrite(str(res_path / \"aligned.png\"), aligned)\n",
    "\n",
    "    # Matches (inliers only)\n",
    "    matchesMask = (mask.ravel().tolist() if mask is not None else None)\n",
    "    vis = cv2.drawMatches(ref_gray, kp1, tgt_gray, kp2, good, None,\n",
    "                          matchesMask=matchesMask,\n",
    "                          flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)\n",
    "    cv2.imwrite(str(res_path / \"matches.png\"), vis)\n",
    "\n",
    "    return H_tgt2ref\n",
    "\n",
    "# Run alignment (pages 2 & 3)\n",
    "H = align_images_sift(\n",
    "    image_to_align_bgr=tgt_img_color,\n",
    "    reference_image_bgr=ref_img_color,\n",
    "    max_features=10,           # interpreted as MIN_MATCH_COUNT (tutorial logic)\n",
    "    good_match_precent=0.7     # Lowe-ratio\n",
    ")\n",
    "print(f\"Saved: {res_path}/aligned.png\")\n",
    "print(f\"Saved: {res_path}/matches.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e985611f",
   "metadata": {},
   "source": [
    "### 3) Build the 3-page PDF (Harris, Aligned, Matches) with a large caption\n",
    "\n",
    "Creates `results/assignment_4_pages.pdf`  \n",
    "with page 1 = Harris, page 2 = Aligned, page 3 = Matches, and a clearly visible caption."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "d880ec16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved PDF: results/assignment_4_pages.pdf\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image, ImageDraw, ImageFont\n",
    "\n",
    "def _add_caption(img_path, caption_text):\n",
    "    \"\"\"\n",
    "    Add a prominent caption band on top of an image and return a PIL Image.\n",
    "    Tries to use a TrueType font (DejaVuSans) with a relatively large size.\n",
    "    Falls back to default font if the TTF is unavailable.\n",
    "    \"\"\"\n",
    "    img = Image.open(img_path).convert(\"RGB\")\n",
    "    W, H = img.size\n",
    "\n",
    "    # Try a large TTF font; fallback to default if missing\n",
    "    font = None\n",
    "    for candidate in [\"DejaVuSans.ttf\", \"/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf\"]:\n",
    "        try:\n",
    "            font = ImageFont.truetype(candidate, size=max(18, H // 25))\n",
    "            break\n",
    "        except Exception:\n",
    "            font = None\n",
    "    if font is None:\n",
    "        font = ImageFont.load_default()\n",
    "\n",
    "    # Compute band height based on font metrics\n",
    "    band_h = max(60, H // 12)\n",
    "    band = Image.new(\"RGB\", (W, band_h), color=(240, 240, 240))\n",
    "    draw = ImageDraw.Draw(band)\n",
    "\n",
    "    # Multi-line safe wrap (simple)\n",
    "    margin = 16\n",
    "    draw.text((margin, band_h//2 - 10), caption_text, fill=(0, 0, 0), font=font, anchor=\"lm\")\n",
    "\n",
    "    stacked = Image.new(\"RGB\", (W, H + band_h), color=(255, 255, 255))\n",
    "    stacked.paste(band, (0, 0))\n",
    "    stacked.paste(img, (0, band_h))\n",
    "    return stacked\n",
    "\n",
    "def export_pdf(harris_path, aligned_path, matches_path, out_pdf_path):\n",
    "    caption = \"METHOD: SIFT + FLANN  |  Lowe ratio = 0.7  |  NOTE: features were NOT limited to 10; MIN_MATCH_COUNT = 10\"\n",
    "    p1 = Image.open(harris_path).convert(\"RGB\")\n",
    "    p2 = _add_caption(aligned_path, caption)\n",
    "    p3 = _add_caption(matches_path, caption)\n",
    "    p1.save(out_pdf_path, save_all=True, append_images=[p2, p3])\n",
    "    print(f\"Saved PDF: {res_path}/assignment_4_pages.pdf\")\n",
    "\n",
    "export_pdf(\n",
    "    res_path / \"harris.png\",\n",
    "    res_path / \"aligned.png\",\n",
    "    res_path / \"matches.png\",\n",
    "    res_path / \"assignment_4_pages.pdf\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ikt213",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
